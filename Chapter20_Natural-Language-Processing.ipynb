{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imagine that, for each of some collection of data science–related buzzwords, you have two numbers between\n",
    "# 0 and 100—the first representing how frequently it appears in job postings, the second how frequently \n",
    "# it appears on resumes:\n",
    "\n",
    "data = [ (\"big data\", 100, 15), (\"Hadoop\", 95, 25), (\"Python\", 75, 50),\n",
    "         (\"R\", 50, 40), (\"machine learning\", 80, 20), (\"statistics\", 20, 60),\n",
    "         (\"data science\", 60, 70), (\"analytics\", 90, 3),\n",
    "         (\"team player\", 85, 85), (\"dynamic\", 2, 90), (\"synergies\", 70, 0),\n",
    "         (\"actionable insights\", 40, 30), (\"think out of the box\", 45, 10),\n",
    "         (\"self-starter\", 30, 50), (\"customer focus\", 65, 15),\n",
    "         (\"thought leadership\", 35, 35)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A more interesting approach might be to scatter them so that horizontal position indicates posting popularity \n",
    "# and vertical position indicates resume popularity, which produces a visualization that conveys a few insights\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def text_size(total):\n",
    "    \"\"\"equals 8 if total is 0, 28 if total is 200\"\"\"\n",
    "    return 8 + total / 200 * 20\n",
    "\n",
    "for word, job_popularity, resume_popularity in data:\n",
    "    plt.text(job_popularity, resume_popularity, word,\n",
    "             ha='center', va='center',\n",
    "             size=text_size(job_popularity + resume_popularity))\n",
    "plt.xlabel(\"Popularity on Job Postings\")\n",
    "plt.ylabel(\"Popularity on Resumes\")\n",
    "plt.axis([0, 100, 0, 100])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n-gram Models\n",
    "# The DataSciencester VP of Search Engine Marketing wants to create thousands of web pages about data science \n",
    "# so that your site will rank higher in search results for data science–related terms.\n",
    "\n",
    "# To do this, we’ll need some way of modeling language. One approach is to start with a corpus of documents \n",
    "# and learn a statistical model of language. In our case, we’ll start with Mike Loukides’s essay \n",
    "# “What is data science?” As in Chapter 9, we’ll use requests and BeautifulSoup to retrieve the data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are a couple of issues worth calling attention to. The first is that the apostrophes in the text are \n",
    "# actually the Unicode character u\"\\u2019\". We’ll create a helper function to replace them with normal apostrophes\n",
    "\n",
    "def fix_unicode(text):\n",
    "    return text.replace(u\"\\u2019\", \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7fc41170004b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mparagraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"p\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfix_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparagraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "# The second issue is that once we get the text of the web page, we’ll want to split it into a sequence of words \n",
    "# and periods (so that we can tell where sentences end). We can do this using re.findall()\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = \"http://radar.oreilly.com/2010/06/what-is-data-science.html\"\n",
    "html = requests.get(url).text\n",
    "soup = BeautifulSoup(html, 'html5lib')\n",
    "\n",
    "content = soup.find(\"div\", \"entry-content\")   # find entry-content div\n",
    "regex = r\"[\\w']+|[\\.]\"                        # matches a word or a period\n",
    "\n",
    "document = []\n",
    "\n",
    "for paragraph in content(\"p\"):\n",
    "    words = re.findall(regex, fix_unicode(paragraph.text))\n",
    "    document.extend(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "bigrams = zip(document, document[1:])\n",
    "transitions = defaultdict(list)\n",
    "for prev, current in bigrams:\n",
    "    transitions[prev].append(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we’re ready to generate sentences:\n",
    "\n",
    "def generate_using_bigrams():\n",
    "    current = \".\"   # this means the next word will start a sentence\n",
    "    result = []\n",
    "    while True:\n",
    "        next_word_candidates = transitions[current]    # bigrams (current, _)\n",
    "        current = random.choice(next_word_candidates)  # choose one at random\n",
    "        result.append(current)                         # append it to results\n",
    "        if current == \".\": return \" \".join(result)     # if \".\" we're done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can make the sentences less gibberishy by looking at trigrams, triplets of consecutive words. \n",
    "# (More generally, you might look at n-grams consisting of n consecutive words, but three will be plenty for us.) \n",
    "# Now the transitions will depend on the previous two words:\n",
    "\n",
    "trigrams = zip(document, document[1:], document[2:])\n",
    "trigram_transitions = defaultdict(list)\n",
    "starts = []\n",
    "\n",
    "for prev, current, next in trigrams:\n",
    "\n",
    "    if prev == \".\":              # if the previous \"word\" was a period\n",
    "        starts.append(current)   # then this is a start word\n",
    "\n",
    "    trigram_transitions[(prev, current)].append(next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that now we have to track the starting words separately. We can generate sentences in pretty much the same \n",
    "# way:\n",
    "\n",
    "def generate_using_trigrams():\n",
    "    current = random.choice(starts)   # choose a random starting word\n",
    "    prev = \".\"                        # and precede it with a '.'\n",
    "    result = [current]\n",
    "    while True:\n",
    "        next_word_candidates = trigram_transitions[(prev, current)]\n",
    "        next_word = random.choice(next_word_candidates)\n",
    "        prev, current = current, next_word\n",
    "        result.append(current)\n",
    "\n",
    "        if current == \".\":\n",
    "            return \" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grammars \n",
    "\n",
    "grammar = {\n",
    "    \"_S\"  : [\"_NP _VP\"],\n",
    "    \"_NP\" : [\"_N\",\n",
    "             \"_A _NP _P _A _N\"],\n",
    "    \"_VP\" : [\"_V\",\n",
    "             \"_V _NP\"],\n",
    "    \"_N\"  : [\"data science\", \"Python\", \"regression\"],\n",
    "    \"_A\"  : [\"big\", \"linear\", \"logistic\"],\n",
    "    \"_P\"  : [\"about\", \"near\"],\n",
    "    \"_V\"  : [\"learns\", \"trains\", \"tests\", \"is\"]\n",
    "}\n",
    "\n",
    "# “So, for example, \"_S\" is the “sentence” rule, which produces a \"_NP\" (“noun phrase”) rule followed by a \"_VP\" \n",
    "# (“verb phrase”) rule. The verb phrase rule can produce either the \"_V\" (“verb”) rule, or the verb rule followed \n",
    "# by the noun phrase rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python', 'trains', 'logistic', 'data science', 'about', 'logistic', 'Python']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How do we generate sentences from this grammar? We’ll start with a list containing the sentence rule [\"_S\"]. \n",
    "# And then we’ll repeatedly expand each rule by replacing it with a randomly chosen one of its productions. \n",
    "# We stop when we have a list consisting solely of terminals\n",
    "\n",
    "['_S']\n",
    "['_NP','_VP']\n",
    "['_N','_VP']\n",
    "['Python','_VP']\n",
    "['Python','_V','_NP']\n",
    "['Python','trains','_NP']\n",
    "['Python','trains','_A','_NP','_P','_A','_N']\n",
    "['Python','trains','logistic','_NP','_P','_A','_N']\n",
    "['Python','trains','logistic','_N','_P','_A','_N']\n",
    "['Python','trains','logistic','data science','_P','_A','_N']\n",
    "['Python','trains','logistic','data science','about','_A', '_N']\n",
    "['Python','trains','logistic','data science','about','logistic','_N']\n",
    "['Python','trains','logistic','data science','about','logistic','Python']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do we implement this? Well, to start, we’ll create a simple helper function to identify terminals:\n",
    "\n",
    "def is_terminal(token):\n",
    "    return token[0] != \"_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we need to write a function to turn a list of tokens into a sentence.\n",
    "\n",
    "def expand(grammar, tokens):\n",
    "    for i, token in enumerate(tokens):\n",
    "\n",
    "        # skip over terminals\n",
    "        if is_terminal(token): continue\n",
    "\n",
    "        # if we get here, we found a non-terminal token\n",
    "        # so we need to choose a replacement at random\n",
    "        replacement = random.choice(grammar[token])\n",
    "\n",
    "        if is_terminal(replacement):\n",
    "            tokens[i] = replacement\n",
    "        else:\n",
    "            tokens = tokens[:i] + replacement.split() + tokens[(i+1):]\n",
    "\n",
    "        # now call expand on the new list of tokens\n",
    "        return expand(grammar, tokens)\n",
    "\n",
    "    # if we get here we had all terminals and are done\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we can start generating sentences:\n",
    "\n",
    "def generate_sentence(grammar):\n",
    "    return expand(grammar, [\"_S\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An Aside: Gibbs Sampling\n",
    "\n",
    "# Gibbs sampling is a technique for generating samples from multidimensional distributions when we only know\n",
    "# some of the conditional distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# “For example, imagine rolling two dice. Let x be the value of the first die and y be the sum of the dice, \n",
    "# and imagine you wanted to generate lots of (x, y) pairs. In this case it’s easy to generate the samples directly:\n",
    "\n",
    "def roll_a_die():\n",
    "    return random.choice([1,2,3,4,5,6])\n",
    "\n",
    "def direct_sample():\n",
    "    d1 = roll_a_die()\n",
    "    d2 = roll_a_die()\n",
    "    return d1, d1 + d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But imagine that you only knew the conditional distributions. The distribution of y conditional on x is easy—if \n",
    "# you know the value of x, y is equally likely to be x + 1, x + 2, x + 3, x + 4, x + 5, or x + 6:”\n",
    "\n",
    "def random_y_given_x(x):\n",
    "    \"\"\"equally likely to be x + 1, x + 2, ... , x + 6\"\"\"\n",
    "    return x + roll_a_die()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you know that y is 2, then necessarily x is 1 (since the only way two dice can sum to 2 is if both\n",
    "# of them are 1). If you know y is 3, then x is equally likely to be 1 or 2. Similarly, if y is 11, then \n",
    "# x has to be either 5 or 6\n",
    "\n",
    "def random_x_given_y(y):\n",
    "    if y <= 7:\n",
    "        # if the total is 7 or less, the first die is equally likely to be\n",
    "        # 1, 2, ..., (total - 1)\n",
    "        return random.randrange(1, y)\n",
    "    else:\n",
    "        # if the total is 7 or more, the first die is equally likely to be\n",
    "        # (total - 6), (total - 5), ..., 6\n",
    "        return random.randrange(y - 6, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The way Gibbs sampling works is that we start with any (valid) value for x and y and then repeatedly \n",
    "# alternate replacing x with a random value picked conditional on y and replacing y with a random value \n",
    "# picked conditional on x. After a number of iterations, the resulting values of x and y will represent \n",
    "# a sample from the unconditional joint distribution:\n",
    "\n",
    "def gibbs_sample(num_iters=100):\n",
    "    x, y = 1, 2 # doesn't really matter\n",
    "    for _ in range(num_iters):\n",
    "        x = random_x_given_y(y)\n",
    "        y = random_y_given_x(x)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can check that this gives similar results to the direct sample:\n",
    "\n",
    "def compare_distributions(num_samples=1000):\n",
    "    counts = defaultdict(lambda: [0, 0])\n",
    "    for _ in range(num_samples):\n",
    "        counts[gibbs_sample()][0] += 1\n",
    "        counts[direct_sample()][1] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic Modeling\n",
    "\n",
    "# A more sophisticated approach to understanding our users’ interests might try to identify the topics that \n",
    "# underlie those interests. A technique called Latent Dirichlet Analysis (LDA) is commonly used to identify \n",
    "# common topics in a set of documents. We’ll apply it to documents that consist of each user’s interests.\n",
    "\n",
    "# There is a random variable that assigns each topic an associated probability distribution over words. \n",
    "# You should think of this distribution as the probability of seeing word w given topic k.\n",
    "# There is another random variable that assigns each document a probability distribution over topics. \n",
    "# You should think of this distribution as the mixture of topics in document d.\n",
    "# Each word in a document was generated by first randomly picking a topic (from the document’s distribution \n",
    "# of topics) and then randomly picking a word (from the topic’s distribution of words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To start with, we’ll need a function to randomly choose an index based on an arbitrary set of weights:\n",
    "\n",
    "def sample_from(weights):\n",
    "    \"\"\"returns i with probability weights[i] / sum(weights)\"\"\"\n",
    "    total = sum(weights)\n",
    "    rnd = total * random.random()      # uniform between 0 and total\n",
    "    for i, w in enumerate(weights):\n",
    "        rnd -= w                       # return the smallest i such that\n",
    "        if rnd <= 0: return i          # weights[0] + ... + weights[i] >= rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# “For instance, if you give it weights [1, 1, 3] then one-fifth of the time it will return 0, one-fifth of \n",
    "# the time it will return 1, and three-fifths of the time it will return 2.\n",
    "# Our documents are our users’ interests, which look like:\n",
    "\n",
    "documents = [\n",
    "    [\"Hadoop\", \"Big Data\", \"HBase\", \"Java\", \"Spark\", \"Storm\", \"Cassandra\"],\n",
    "    [\"NoSQL\", \"MongoDB\", \"Cassandra\", \"HBase\", \"Postgres\"],\n",
    "    [\"Python\", \"scikit-learn\", \"scipy\", \"numpy\", \"statsmodels\", \"pandas\"],\n",
    "    [\"R\", \"Python\", \"statistics\", \"regression\", \"probability\"],\n",
    "    [\"machine learning\", \"regression\", \"decision trees\", \"libsvm\"],\n",
    "    [\"Python\", \"R\", \"Java\", \"C++\", \"Haskell\", \"programming languages\"],\n",
    "    [\"statistics\", \"probability\", \"mathematics\", \"theory\"],\n",
    "    [\"machine learning\", \"scikit-learn\", \"Mahout\", \"neural networks\"],\n",
    "    [\"neural networks\", \"deep learning\", \"Big Data\", \"artificial intelligence\"],\n",
    "    [\"Hadoop\", \"Java\", \"MapReduce\", \"Big Data\"],\n",
    "    [\"statistics\", \"R\", \"statsmodels\"],\n",
    "    [\"C++\", \"deep learning\", \"artificial intelligence\", \"probability\"],\n",
    "    [\"pandas\", \"R\", \"Python\"],\n",
    "    [\"databases\", \"HBase\", \"Postgres\", \"MySQL\", \"MongoDB\"],\n",
    "    [\"libsvm\", \"regression\", \"support vector machines\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to calculate the sampling weights, we’ll need to keep track of several counts. Let’s first create\n",
    "# the data structures for them.\n",
    "\n",
    "# How many times each topic is assigned to each document:\n",
    "\n",
    "# a list of Counters, one for each document\n",
    "\n",
    "from collections import Counter\n",
    "document_topic_counts = [Counter() for _ in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many times each word is assigned to each topic:\n",
    "\n",
    "# a list of Counters, one for each topic\n",
    "\n",
    "K=4 #topics\n",
    "\n",
    "topic_word_counts = [Counter() for _ in range(K)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The total number of words assigned to each topic:\n",
    "\n",
    "# a list of numbers, one for each topic\n",
    "topic_counts = [0 for _ in range(K)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The total number of words contained in each document:\n",
    "\n",
    "# a list of numbers, one for each document\n",
    "document_lengths = map(len, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of distinct words:\n",
    "\n",
    "distinct_words = set(word for document in documents for word in document)\n",
    "W = len(distinct_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And the number of documents:\n",
    "\n",
    "D = len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# “For example, once we populate these, we can find, for example, the number of words in documents[3] \n",
    "# associated with topic 1 as:\n",
    "\n",
    "document_topic_counts[3][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# “And we can find the number of times nlp is associated with topic 2 as:\n",
    "\n",
    "topic_word_counts[2][\"nlp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we’re ready to define our conditional probability functions. Each has a smoothing term that ensures every\n",
    "# topic has a nonzero chance of being chosen in any document and that every word has a nonzero chance of being \n",
    "# chosen for any topic\n",
    "\n",
    "def p_topic_given_document(topic, d, alpha=0.1):\n",
    "    \"\"\"the fraction of words in document _d_\n",
    "    that are assigned to _topic_ (plus some smoothing)\"\"\"\n",
    "\n",
    "    return ((document_topic_counts[d][topic] + alpha) /\n",
    "            (document_lengths[d] + K * alpha))\n",
    "\n",
    "def p_word_given_topic(word, topic, beta=0.1):\n",
    "    \"\"\"the fraction of words assigned to _topic_\n",
    "    that equal _word_ (plus some smoothing)\"\"\"\n",
    "\n",
    "    return ((topic_word_counts[topic][word] + beta) /\n",
    "            (topic_counts[topic] + W * beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We’ll use these to create the weights for updating topics:\n",
    "\n",
    "def topic_weight(d, word, k):\n",
    "    \"\"\"given a document and a word in that document,\n",
    "    return the weight for the kth topic\"\"\"\n",
    "\n",
    "    return p_word_given_topic(word, k) * p_topic_given_document(k, d)\n",
    "\n",
    "def choose_new_topic(d, word):\n",
    "    return sample_from([topic_weight(d, word, k)\n",
    "                        for k in range(K)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# “We start by assigning every word to a random topic, and populating our counters appropriately:\n",
    "\n",
    "import random\n",
    "random.seed(0)\n",
    "document_topics = [[random.randrange(K) for word in document]\n",
    "                   for document in documents]\n",
    "\n",
    "for d in range(D):\n",
    "    for word, topic in zip(documents[d], document_topics[d]):\n",
    "        document_topic_counts[d][topic] += 1\n",
    "        topic_word_counts[topic][word] += 1\n",
    "        topic_counts[topic] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in range(1000):\n",
    "    for d in range(D):\n",
    "        for i, (word, topic) in enumerate(zip(documents[d],\n",
    "                                              document_topics[d])):\n",
    "\n",
    "            # remove this word / topic from the counts\n",
    "            # so that it doesn't influence the weights\n",
    "            document_topic_counts[d][topic] -= 1\n",
    "            topic_word_counts[topic][word] -= 1\n",
    "            topic_counts[topic] -= 1\n",
    "            document_lengths[d] -= 1\n",
    "\n",
    "            # choose a new topic based on the weights\n",
    "            new_topic = choose_new_topic(d, word)\n",
    "            document_topics[d][i] = new_topic\n",
    "\n",
    "            # and now add it back to the counts\n",
    "            document_topic_counts[d][new_topic] += 1\n",
    "            topic_word_counts[new_topic][word] += 1\n",
    "            topic_counts[new_topic] += 1\n",
    "            document_lengths[d] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Java 3\n",
      "0 Big Data 3\n",
      "0 Hadoop 2\n",
      "0 deep learning 2\n",
      "0 artificial intelligence 2\n",
      "0 C++ 2\n",
      "0 neural networks 1\n",
      "0 Storm 1\n",
      "0 programming languages 1\n",
      "0 MapReduce 1\n",
      "0 Haskell 1\n",
      "1 R 4\n",
      "1 statistics 3\n",
      "1 Python 3\n",
      "1 probability 2\n",
      "1 pandas 2\n",
      "1 statsmodels 2\n",
      "1 mathematics 1\n",
      "1 numpy 1\n",
      "1 theory 1\n",
      "1 scipy 1\n",
      "2 HBase 3\n",
      "2 Postgres 2\n",
      "2 MongoDB 2\n",
      "2 Cassandra 2\n",
      "2 NoSQL 1\n",
      "2 MySQL 1\n",
      "2 Spark 1\n",
      "3 regression 3\n",
      "3 libsvm 2\n",
      "3 scikit-learn 2\n",
      "3 machine learning 2\n",
      "3 neural networks 1\n",
      "3 probability 1\n",
      "3 Mahout 1\n",
      "3 Python 1\n",
      "3 decision trees 1\n",
      "3 databases 1\n",
      "3 support vector machines 1\n"
     ]
    }
   ],
   "source": [
    "# “What are the topics? They’re just numbers 0, 1, 2, and 3. If we want names for them we have to do that ourselves.\n",
    "# Let’s look at the five most heavily weighted words for each\n",
    "\n",
    "for k, word_counts in enumerate(topic_word_counts):\n",
    "    for word, count in word_counts.most_common():\n",
    "        if count > 0: print k, word, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on these I’d probably assign topic names:\n",
    "topic_names = [\"Big Data and programming languages\",\n",
    "               \"Python and statistics\",\n",
    "               \"databases\",\n",
    "               \"machine learning\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hadoop', 'Big Data', 'HBase', 'Java', 'Spark', 'Storm', 'Cassandra']\n",
      "Big Data and programming languages 4 databases 3\n",
      "['NoSQL', 'MongoDB', 'Cassandra', 'HBase', 'Postgres']\n",
      "databases 5\n",
      "['Python', 'scikit-learn', 'scipy', 'numpy', 'statsmodels', 'pandas']\n",
      "Python and statistics 5 machine learning 1\n",
      "['R', 'Python', 'statistics', 'regression', 'probability']\n",
      "Python and statistics 4 machine learning 1\n",
      "['machine learning', 'regression', 'decision trees', 'libsvm']\n",
      "machine learning 4\n",
      "['Python', 'R', 'Java', 'C++', 'Haskell', 'programming languages']\n",
      "Big Data and programming languages 4 Python and statistics 1 machine learning 1\n",
      "['statistics', 'probability', 'mathematics', 'theory']\n",
      "Python and statistics 4\n",
      "['machine learning', 'scikit-learn', 'Mahout', 'neural networks']\n",
      "machine learning 4\n",
      "['neural networks', 'deep learning', 'Big Data', 'artificial intelligence']\n",
      "Big Data and programming languages 4\n",
      "['Hadoop', 'Java', 'MapReduce', 'Big Data']\n",
      "Big Data and programming languages 4\n",
      "['statistics', 'R', 'statsmodels']\n",
      "Python and statistics 3\n",
      "['C++', 'deep learning', 'artificial intelligence', 'probability']\n",
      "Big Data and programming languages 3 machine learning 1\n",
      "['pandas', 'R', 'Python']\n",
      "Python and statistics 3\n",
      "['databases', 'HBase', 'Postgres', 'MySQL', 'MongoDB']\n",
      "databases 4 machine learning 1\n",
      "['libsvm', 'regression', 'support vector machines']\n",
      "machine learning 3\n"
     ]
    }
   ],
   "source": [
    "# at which point we can see how the model assigns topics to each user’s interests:\n",
    "\n",
    "for document, topic_counts in zip(documents, document_topic_counts):\n",
    "    print document\n",
    "    for topic, count in topic_counts.most_common():\n",
    "        if count > 0:\n",
    "            print topic_names[topic], count,\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
